---
layout: post
title: NBA Player Salaries
---

 In this post I will use a variety of linear regression techniques to try to understand NBA player salaries. I will be guided by two questions: 1) Can future player salary be predicted by past player performance? 2) What should an aspiring NBA player do to maximize their salary in the NBA? 

 The data for this project was scraped from [Basketball Reference](http://www.basketball-reference.com/). In particular, I gathered data from all players who played in both the 2016 and 2017 seasons. I tried throughout to predict the player's 2017 salary based on their 2016 performance. There are a number of challenges facing this strategy. One is that players typically sign mutli-year contracts that may or may not possible for the player to break. Consequently, any given year, some subset of players will negotiate a new contract. Moreover, rookie's (players who have fewer than 3 years experience in the NBA) contracts follow a different set of fairly restrictive rules: basically, a rookie's salary is determined by the order in which he was drafted, the year he joined the NBA. For this reason, I dropped the rookies from my data set. This left 270 players who played in both 2016 and 2017. For the reasons discussed above, only a subset of these players actually signed a new contract in 2017. I chose to keep the full 270 for two reasons: first, the sample size is already small, and would decrease further to roughly 90 if we restricted to players who signed a new contract and, secondly, one may assume that for the majority of players, their performance doesn't vary too dramatically from year to year.

 One more note on assumptions, regarding the second question. This question is a bit tongue-in-cheek: obviously simply getting in to the NBA is difficult and rare enough. An aspiring player should probably practice whatever it is that will get him in the league, without regard to how much he will be paid once he is in. However, I still find it an interesting question to bear in mind: what sorts of players and skills are most valued?

Before we introduce the first model, let's take a look at the player features that I initially considered

![Initial Features](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/post2/images/Feature_List.png)

 A quick note on "web scraping" for those who are unfamiliar. Basically, one can obtain the html underlying most websites. One can then use python (and probably most other languages) to search, filter, and compile the contents thereof. There are a number of libraries available to streamline the process. I used [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/).

For the first linear model, I performed a simple ordinary least squares linear regression. I used this model to check if linear regression is even an appropriate way to model NBA player salary based on the above features. The QQ plot below suggests linearity is a reasonable assumption. Moreover, the scatter plot shows a bit of Heteroscedasticity, but not a problematic amount. Also note that I removed some blatant multi-collinearity: FGA=2PA+3PA.

![QQ Plot](https://github.com/michaelaaroncantrell/michaelaaroncantrell.github.io/blob/master/_posts/post2/images/qq_plot.png?raw=true)
![Residual Plot](https://github.com/michaelaaroncantrell/michaelaaroncantrell.github.io/blob/master/_posts/post2/images/error-scatter.png?raw=true)

Using the first model, I made a second model using only the features with a P-value of at most 0.1. Below is a plot of predicted salary versus actual salary for the second model. 

![Significant Features Plot](https://github.com/michaelaaroncantrell/michaelaaroncantrell.github.io/blob/master/_posts/post2/images/signif-scatter.png?raw=true)

If the model were perfect, then all of the blue dots would lie on the red line. I computed $R^2$ by using sklearn to run a 5-fold [cross-train-split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). The value of 0.5 is the mean of the test data's $R^2$ values. All of the values of $R^2$ I report in this post are computed this way. 

Below you'll see a plot of the difference between the player's actual salary and the predicted salary, and a list of the top 5 underpaid and overpaid players (according to my model).

[Errors for Significant Features Plot](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/post2/images/signif-errors.png?raw=true)
[Underpaid Players](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/post2/images/signif-underpaid.png)
[Overpaid Players](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/post2/images/signif-overpaid.png)

 Interestingly enough, C.J. McCollum, who my model reports should be paid $18 Million (but is only paid $3 Million) won the NBA's most improved player of 2016! Looking at his [page](http://www.basketball-reference.com/players/m/mccolcj01.html), it appears that his 2017 salary (which I was trying to predict) was the final year of his 3-year contract. The following year, he signed a new contract, with a 2018 salary of $24 million, much closer to my prediction. It looks like [Giannis Antetokounmpo](http://www.basketball-reference.com/players/a/antetgi01.html) (another of our underpaid players) is in a similar position (he'll receive 22 Million in 2018).

Let's take a closer look at the features that our P<0.1 threshold selected. 

[Significant Features](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/post2/images/Signif-feats.png)

Notice that two categories - team and position - made the cut. More specifically, the distribution of salaries amongst point guards (Pos[T.PG]) was unlikely to be due to chance. Similarly, the distribution of salaries amongst Philly, Denver, and the LA Lakers were unlikely to be due to chance. Since at least one of the values in the categories "position" and "team" had an appreciable P-value, I kept all values in both categories in my model.

Is it meaningful/informative to use a player's team to predict his salary? If nothing else, it is certainly interesting. The graph below shows the salaries of the players on team Philly against the salaries of the rest of the NBA. 

[Philly's Player's Salaries](link)*****!$!*@&%@*%(@()%@(%@()%(@)%(@%)(@)))

We certainly learn a lot about a player's salary by knowing that he plays for Phily. But I believe this tells us more about the Philly franchise than it does about *why* the players on Philly are paid poorly. It is more interesting to understand what features *of the player* influence his salary.

For our third model, let's use all variables in our initial list *except* the team. The resulting test-data $R^2$ is the same as it was in the second model. Moreover this model is more meaningful for our purposes. It's not perfect, though. Ranking the correlation of each of the features in this model individually with salary, we see that the *number of field goal attempts* a player takes is most correlated with salary. 

[Non-Team Correlation](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/post2/images/non_team_correlation.png)

Does this mean that players get paid more for taking more shots??? Certainly not. What we see here is that the highest paid players take the most shots. This makes perfect sense: the coach wants the best (most expensive) player taking the most shots.

For this reason, for the fourth model, I chose to keep only features that are *improvable*, and not under direction of the coach. There is some nuance here, but for simplicity I will assume that a coach would always prefer every player to get more steals, for example (though attempting and failing to make a steal negatively impacts the team - this is a calculated risk). Therefore, number of steals per game goes in to the pool of improvable features, while the number of field goal attempts does not. Thus we arrive at our fourth model, which uses all such *improvable* features (I included height and weight as well). 

[Improvable Features](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/post2/images/Impr-Feats-corr.png)

The improvables model scores $R^2\approx 0.43$. This is a bit weaker than the previous models in terms of predictive power (0.5), but it is much more meaningful. Which of the individual improvable features do you think has the highest correlation with player salary? Personally, I guessed either 2 Point Percantage or 3 Point Percantage. Take a look at how badly 3 Point Percantage predicts player salary.

[3 Point Percentage vs. Salary](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/post2/images/3PP-scatter.png)

 Not so useful. To my surprise, the most predictive improvable feature is defensive rebounds! 

[Defensive Rebounds vs. Salary](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/post2/images/DRB-scatter.png)

 Finally, here's a plot of the predicted versus actual salaries for our improvables model. 

[Improvable Feature Model](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/post2/images/Impr-scatter.png)

 Note that the fourth model was built from a Lasso regularization beginning with all improvable features. As expected, Lasso gave the largest coefficient to Defensive Rebounds, with Assists coming in second. It's also morally reassuring to see that personal fouls received a negative coefficient.

 [Improvable Lasso Coefficients](https://github.com/michaelaaroncantrell/michaelaaroncantrell.github.io/blob/master/_posts/post2/images/Impr-Lasso-coef.png?raw=true)

Finally, we've been manually selecting features based on P-values and interpretability. Let's check to see what features a Lasso regularization selects if we feed it all of our initial features, and what kind of predictive power it has. It would be great if it was highly predictive and selected meaningful features! I again used sklearn and first made a plot of the mean squared error against the (log of) regularization parameter $\alpha$.

 [Lasso Regularization on All Features](https://github.com/michaelaaroncantrell/michaelaaroncantrell.github.io/blob/master/_posts/post2/images/Lasso-alpha.png?raw=true)

 It looks like we should be trying to find that second trough near 10,000. Running a 5-fold cross-train-split and repeatedly narrowing my range, I found $\alpha \approx 14000$ to be about optimal with an $R^2 \approx 0.53$. This is a modest improvement from our previous models. However, this Lasso model selected *mostly* team features. 

 [Lasso Coefficients on All Features](https://github.com/michaelaaroncantrell/michaelaaroncantrell.github.io/blob/master/_posts/post2/images/Lasso-features.png?raw=true)

 Here's a plot of the Lasso model - it would be hard to pick this model out of a crowd with our other models, and it mostly tells a story about the teams.

 [Lasso on All Features Model](https://github.com/michaelaaroncantrell/michaelaaroncantrell.github.io/blob/master/_posts/post2/images/Lasso-scatter.png?raw=true)

In conclusion, NBA player salaries are fairly predictable using linear regression, with $R^2\approx 0.53$. However, the most predictive features - team membership and field goal attempts - don't really reflect what skills are most valuable in the NBA. Zeroing in on the features which do reflect player's skills, we retain most of our predictive power ($R^2\approx 0.43$). Moreover, the most predictive features of this model are a bit surprising: defensive rebounds, assists and turnovers top the list.

Given more time, it would be great to use data from more years. One option would be to adjust the salaries for inflation and treat other pairs of (performance in year y, salary in year y+1) as instances. A second option would be to perform time series analysis. A third option would be to select only those players who actually sign a new contract during a given year. That's all from me for now, however. Here's my [source code](***LINK***) for this project. Up next: classification techniques. Thanks for reading! 


