---
layout: post
title: Predicting Flight Delays
---

 In this post I'll report on my efforts to predict whether or not a flight will be delayed. I will discuss the implementation and effectiveness of several machine learning classification algorithms, as well as my first interaction with amazon web services (aws), postgres databases, and D3 visualization.

 If you've flown a dozen times, it's likely you've experienced a delayed flight, and I don't need to convince you that predicting delays is useful. In fact, if you've flown a dozen times, there's a 90% chance your flight has been delayed - that's because about 17% of flights are delayed.

![Annual Flight Delays](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/Flight_Delays/images/Delayed17.png)

Moreover, according to a 2010 study by the Federal Aviation Administration, airline delays cost consumers (airline companies) about $19 ($9) Billion annually. 

The data I'm using for this post is from the [Bureau of Transportation Statistics](http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236). I gathered data on every domestic flight in 2016 on all major commercial carriers (actually, December wasn't available yet, so I used December 2015). This totalled over 5.5 Million flights, and I worked with about 700 features (I used dummy variables for origin and destination airport). The shear size of the data set presented its own challenges and lessons, to which I will turn first.

At first I tried to perform analysis on my personal computer. But these computations quickly crashed my computer. And that's why people use cloud computing! I rented a computer from [aws](https://aws.amazon.com/) and used postgres to load the data into a sql database. I used sql queries for my initial exploratory analysis since they are much quicker than pandas (which I usually use). At first I tried to work with all of the data, but quickly realized this would slow me down dramatically. Moreover, I tested a naive logistic regression and random forest (with sklearn and cross train split) on the full data set and on a random subsample of size 100,000, and the results were almost identical. So I decided to run the rest of my analysis on this subsample, and to come back to the full sample if a company wanted to fund the project ::smiley::. 

Here are a few visualizations of the full 5.5M data set. The first graph shows the percentage of flights delayed by airline carrier, and suggests that Spirit's reputation is deserved. The next graph reveals that Saturday has the fewest flights, but that the percentage of delays by day of the week does not vary dramatically.

![Delays By Airline](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/Flight_Delays/images/DelayedAirline.png)

![Delays by Day](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/Flight_Delays/images/DelayedDaily.png)

Now let's turn to the models. Even on the reduced sample size, SVM was incredibly slow. Moreover a few tests with a few hyper-parameters indicated that SVM wouldn't perform the best, so I discarded that algorithm. That left me with logistic regression, random forest, naive Bayes, and KNN. I ran a cross-validated grid-search on many of the hyper-parameters of the models, in addition to the over-sampling ratio. Since this problem has significant class imbalance, I used [imblearn random over sampler](http://contrib.scikit-learn.org/imbalanced-learn/generated/imblearn.over_sampling.RandomOverSampler.html). 

Here's a graph of the ROC curves for the best-tuned versions of each of my algorithms. The [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) for a given algorithm is a plot of the false positive rate (FPR) versus the true positive rate (TPR) as the probability threshold varies from 0 to 1. More precisely, each algorithm yields a *probability* for each flight to be either delayed or not delayed. For example, for a threshold of 0.5, if a sample has a probability greater than .5 of being delayed, then the flight is classified as delayed. But say for example we want to be sure to catch all of the delayed flights, even at the cost of flagging as delayed, flights with a lower probability of being delayed. Then we move the threshold, say, to 0.3. For each such threshold, on the test set we get a FPR and TPR, and plot this on the ROC curve. For example, if we lower the threshold to 0.3, we expect both our TPR and FPR to increase, since we are flagging more flights as delayed (positive).

The ideal point on the ROC curve is the upper left hand corner, and, more generally, the closer the curve is to the upper left hand corner, the better. On the other hand, the closer it is to the line y=x, the worse the algorithm. One way to measure the goodness of the ROC curve is the area under the curve. I used this metric throughout to tune the hyper-parameters and select the best models (I'll say why below). Using this metric, we see that the random forest classifier is the best model.

However, the logistic regression model is not far behind the random forest, and it is much more intepretable. Since I am interested in understanding what features are driving the model, I chose to explore the logistic regression further. In particular, I extracted the features and their coefficients and used [D3](https://d3js.org/) to visualize the importance of each feature. The features I included are airline, origin, destination, month, day of week, departure hour, arrival hour, and two features I engineered: congestion and adjusted congestion. I calculated congestion by summing the number of other planes arriving or departing from the same airport in the same hour window on the same day. I then calculated the median congestion over all days, and took the difference between the median and daily congestion to get the 'adjusted congestion'. This was meant to represent an unusally busy (or not busy) day at the airport. Below you'll see my D3 visualization of the importance of the features. The larger the bubble, the more influential the feature. The Blue features are negative, in the sense that having it increases your chance of delay. The orange bubbles enclose features with a positive effect, in the sense that having it decreases your chance of delay. Thus, as expected, we see that flying Spirit, out of Newark, in to LaGuardia, on Fridays, and leaving at 5pm all increase your chance of delay. On the other hand, departing at midnight, in July on Hawaiian airlines decreases your chance of delay. The results mostly conform to our prejudices. I was disappointed to see that the congestion and adjusted congestion played almost no role in the model (can you even find their bubbles?).

![Feature Importance](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/blob/master/_posts/Flight_Delays/images/All-Bubbles.pdf)

I wasn't too impressed with my best model on all flights, and began to wonder how to improve the model. I decided to introduce weather data. The FAA reports that about 69% of flight delays are caused by weather. Personally, I don't believe this statistic; I believe that airlines blame the weather whenenver they can so that they don't get blamed. Poking around the internet, it seems that aircraft maintenance is a major cause for delay. In any case, I don't have access to maitenance logs and the like, so I settled on weather data, which is easily available. In particular I turned to the [NOAA](https://www7.ncdc.noaa.gov/CDO/cdopoemain.cmd?datasetabbv=DS3505&countryabbv=&georegionabbv=NAMER&resolution=40). I couldn't find an easy way to extract weather data from every airport in my data set, since the NOAA names for the weather stations at the airports don't follow any particular formula. I.e. it would be great if the weather station at the airport used the airport code, e.g. JFK, but they don't. So I decided for the sake of time and for proof of concept that I would choose one flight to analyze with weather data. I chose the flight from JFK to LAX since it is popular (3rd in number of flights per year), spans different climates, and moves lots of passengers.

From the NOAA I gathered temperature, max and min daily temperature, precipation, snow fall, visibility, wind speed and wind gusts. The data was a bit messy, with irregular data collection and many missing values. It was easy to judiciously choose either the max or min for multiple observations in an hour (whichever was more likely impactful on delays), and to use the median in most cases to fill in missing values. I combined this with the features listed above and ran the same models in the same way: cross-validated with a grid-search on hyper-parameters optimizing for area under the ROC curve. Again logistic regression and random forest had the best performance. KNN probably suffered from the 'curse of dimensionality' and Naive Bayes was probably a little too naive (the features are not close to independent). Here are the ROC curves for the different models.

![Weather Model Performance](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/Flight_Delays/images/model-comparison.png)


I made a similar D3 visualization of the importance of the different features for logistic regression in this case. Again Blue indicates a negative effect. Since there are continuous variables in this case, it is worth noting that the more of a blue feature, like wind speed, the more likely a delay. Similarly, the more of an orange feature, like visibility, the less likely a delay. Can you guess why "time scheduled" is the most influential feature?

![Weather Features](link***)

Take a look at a side-by-side comparison of the two logistic ROC curves with and without the weather data. It is clear that the weather data made a significant difference. It would be great to automate collection of weather data on all of the airports in my data set. Unfortunately I don't have time for that now.

![Side by Side](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/Flight_Delays/images/LR-ROC.png) ![Side by side](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/Flight_Delays/images/Weather-LR-ROC.png)

I have been working on making a (admittedly crude) web app which would allow a user to interactively choose the characteristics of their flight (day of week, month, airline, origin, destination) and see the probability of the chosen flight being delayed, in real time. Hopefully I'll learn enough javascript and html to make the web app come to life before too long. 

I want to finish with a comment about my choice of ROC area under the curve as my guiding metric for this project. You can think of the ROC curve as offering a continuum of choices of costs and benefits. The cost is the FPR and the benefit is the TPR. If you are an airline, for example, you may want to be able to predict which of your flights will be delayed so that you can reroute passengers, employees, make accomodations, etc. In this case, the benefit is avoiding the cost of idle employees, and accomodating and angering passengers. The cost is mistakenly flagging certain flights as delayed which in fact will be on time. Depending on the actual costs involved in both of these, the airline would pick a different point on the ROC curve to optimize their bottom line.

The calculation is similar for an individual. Depending on how much my time is worth and how much I am annoyed by waiting at the airport, I will pick a different threshold for TPRs and FPRs. For example, if I have lots of time and am easy going, but lack money, I would only avoid flights that are nearly certain to be delayed. I would choose a point near the origin of the ROC curve, and my list of available flights would still include many Spirit flights leaving at 5pm in high winds. On the other hand, if my time is extremely valuable, I would choose a higher threshold (a point farther up and to the right on the ROC curve), and be ok with having ignored some cheaper flights with a modest chance of delay. In this way the ROC curve is flexible in its business applications. Of course, if I had a specific client, I would optimize all of my algorithms to their needs. If you're interested, let me know!

That's all for now! Here's a [link to my source code](link***). Up next: natural language processing. Thanks for reading!