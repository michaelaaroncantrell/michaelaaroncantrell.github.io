---
layout: post
title: NLP Music Recommender
---

Today's post is about how I used natural language processing (NLP) to build a music recommendation system, musical mashup engine, and a text-input only recommendation system. [Click here to go play with the tools on my webpage.](http://michaelaaroncantrell.pythonanywhere.com/) This is my final project for my data science bootcamp [Metis](https://www.thisismetis.com/). I'll start out with a high level overview and then jump in to the weeds.

My initial idea for the project was to use the nuance of language to uncover similarities in music not captured by traditional recommendation systems. This idea worked... too well. That is to say, I found extremely interesting and unpredictable relationships between music, but I was afraid the consumer might want something a little more predictable. For example, from Radiohead's OK Computer the 3rd recommendation I produced was an album by Daryl Hall & John Oates. I had never heard of these folks (go listen to them). Sure enough, I was struck by the similarity in their poppiness, electronica and what I would describe as ethereal-ness of the music. Nevertheless, this music is from the 70s, and might not be what someone is expecting based off of the Radiohead input. 

To remedy this, I also built my take on the traditional collaborative filter, originally pioneered by Amazon ("Users who bought X frequently also bought Y"). Like Amazon and thousands of others before me, I used data on users ratings of different albums and Singular Value Decomposition to build this collaborative filter. Finally, I combined these two recommenders with a view towards unusual but favorable recommendations. I did this by creating a threshold toggle, set by default to 60%, so that only NLP recommendations that fall in the top 60% of the collaborative filter become final recommendations. In this way, I found the most interesting NLP recommendations, but filtered out those that are too bizarre. Moreover, on my website, the user can play with the threshold to obtain more or less experimental recommendations. 

![Interactive Recommendation Process](https://github.com/michaelaaroncantrell/michaelaaroncantrell.github.io/blob/master/_posts/NLP_music/images/RecProcess.png)

After having created the NLP recommender, I realized I could easily extract more value from my efforts. Basically, I had projected all albums in to a 30 dimensional space representing the words people use to describe the albums. It is then easy to write a new description of an album you would like to hear, project it in to this 30 dimensional space, and then find the closest album. The result is the album which other people had described most similarly to how you described what you wanted to hear. This is the Free Form Text Recommender on my website.

Having represented albums as vectors, we can do other fun things like add two albums and find the nearest album to the result. Since we're using the angle between albums to judge distance, this is the same as averaging the two vectors. In this way we find the musical love child of the two albums. This is the Musical Mashup on my website. For example, mashing up N.W.A.'s Straight Outta Compton (rap music) and Johnny Cash's At Folsom Prison (country/folk/rock) results in Kid Rock and Linkin Park, which are in my mind the musical love children of N.W.A. and Johnny Cash.

It's worth pointing out that is also easy to perform analogies, like the famous Word2Vec example of King - Man + Woman = Queen. This wasn't as exciting to me as the three products above, but is low hanging fruit once you've done the work of vectorizing your items (literally one line of code). Turning your products in to meaningful vectors is useful and interesting!

If you haven't gone to the website and played yet, go! Then we'll jump in to the details of my project.

I'm going to focus on the NLP recommender part of my project, since it is the more innovative and interesting part. Here's [a great paper](http://herbrete.vvv.enseirb-matmeca.fr/IR/CF_Recsys_Survey.pdf) describing collaborative filtering.

I used a large database of amazon reviews [found here](http://jmcauley.ucsd.edu/data/amazon/) courtesy of R. He, J. McAuley, C. Targett, J. Shi and A. van den Hengel. I put the entire CD & Vinyl database into MongoDB on an AWS instance. Due to the size of the data set, I decided to subset on reviews from 2004 to 2013 and to CDs with at least 20 reviews. The resulting data set consisted of ~170,000 reviews of ~4,000 unique CDs. I broke the reviews up in to (500,000+) individual sentences so that one reviewer could assess several independent aspects of the music. Due to the size of the data set, I did all of my work "in the cloud" on an AWS instance.

The tools that proved most useful for me were non-negative matrix factorization (NMF) and count vectorizer (CV). Count vectorizer took the 500K sentences and looked at the words that occur in each sentence. I chose an n-gram size of 2, so CV also counted instances of pairs of consecutive words, such as "great band". I also chose a threshold of frequency of occurences of a word, so that if a word was too common, it was ignored all together. One wants to exclude common and uninformative words like "very good".

I tried playing with TFIDF (term-frequency inverse document-frequency) which weights the occurences of words by the rarity of the word in the entire list of sentences, but CV gave superior results. My hunch is that this is due to the sparsity of the language used: each sentence was chock full of specialized language rarely found in the other reviews, without enough overlap to connect the sentences. Instead the not-common-but-not-too-uncommon words such as rhythm, guitar, vocals, or blues were more meaningful than the rarer words.

So CV turned the family of sentences in to a bunch of vectors (hence the name), labelled by the number of occurences of each word. We now feed this vectorization in to NMF. The idea behind NMF is to assume that the documents are written about some number of topics, say "cats, dogs, airplanes". We further assume that, each document on each particular topic is a random selection of some words, with some probability distribution. For example, each document in the "cats" topic is written by selecting from the words (cat, meow, sleep, play, eat) with probabilities (.5, .2, .1, .1, .1). So a typical document about cats might be "cat cat meow eat cat". Of course this is just a silly example. But what NMF does is *make* this assumption, and then try to learn the topics (cats, dogs, airplanes) and the words associated to each topic (cat, meow, sleep, play, eat) along with their probabilities (.5, .2, .1, .1, .1) to reconstruct the actual sentences fed to it.

![NLP Process](https://raw.githubusercontent.com/michaelaaroncantrell/michaelaaroncantrell.github.io/master/_posts/NLP_music/images/NLPProcess.png)

I played at great length with the number of topics and the frequency threshold (and other tools such as TFIDF, LDA, and PCA) to find the best breakdown of topics. For each iteration, I checked the most probable words in each topic to get a sense of what the topic was about. In the end I settled on generating 30 topics, six of which I threw out (e.g. those about the amazon delivery, the cost, etc.). I also chose names for each topic based on the words that appeared with the highest probability in each topic. See below for the topic names.

Next I wanted to give a score for each album and for each topic. Given a sentence, NMF generates a probability that the sentence belongs to each topic. So, on the one hand I calculated this probability vector. On the other hand, I used a tool called TextBlob to analyze the sentiment of the sentence. The sentiment is a value from -1 to 1 judging how negative or positive a sentence is. For example, "The absolute worst terrible sad" would receive a score close to -1. Finally, I multiplied the probability vector by the sentiment, to obtain a rating on every topic for the album which the sentence was about. Thus "the absolute worst terrible sad guitar" would generate a very negative score in the "guitar" topic. To get one score for the album, I averaged this procedure over all sentences reviewing a given album. Here's an example of the Smashing Pumpkin's Mellon Collie & The Infinite Sadness and its score. You can also see the names I chose for each of the topics. This album scored highest in the "guitar" and "female/writing" categories.

![Smashing Pumpkins As NLP Vector](https://github.com/michaelaaroncantrell/michaelaaroncantrell.github.io/blob/master/_posts/NLP_music/images/VectorExample.png)

At this point we almost have the recommendation system! Notice what we have done: we have represented each album as a point in a 24 dimensional vector space. If the topics we learned from NMF and the user reviews were meaningful, then albums whose vectors are close to each other should be similar. Rather than finding the nearest vectors using the usual Euclidean distance, I followed conventional wisdom and decided that two vectors are close if the angle between them is small. The idea here is that music with the same *proportion* of each feature (e.g. rock and folk) are similar, and that the angle captures this closeness of proportionality. 

Here's a visualization of why the top recommendation for the Smashing Pumpkin's album above is Radiohead's Hail To The Thief. Since cosine distance only cares about the relative proportions of the values in each coordinate, Pie Charts are actually accurate representations of the albums as vectors.

![Pumpkins and Radiohead as Pie Charts](https://github.com/michaelaaroncantrell/michaelaaroncantrell.github.io/blob/master/_posts/NLP_music/images/PieCharts.png)

That's all from me for now. You can find the source code for this project [here](https://github.com/michaelaaroncantrell/Word-Riff/blob/master/finalproject.ipynb). Note that the code is seriously computationally intensive and may crash your computer, so be careful!

Soon I hope to have time to blog about my work in progress performing style transfer for text. [Style transfer for images](http://genekogan.com/works/style-transfer/) is beautiful and fascinating. For example, it takes your favorite image as input and produces a new image that looks like your image but as if it were painted in the style of Van Gogh's Starry Night. I would like to build the analogous ability for text: you give me a sentence you want to text to your friend, and I transform it in to a new sentence that *means* the same thing as your sentence, but reads as if Jane Austen had written it. I have built a metric for whether or not Jane Austen wrote the sentence, but the trouble is determining if two sentences mean the same thing. Solving this sub-problem is an active area of research, so my optimism is duly tempered.

By the way, I finished my bootcamp a few weeks ago and am on the job market! If you or someone you know are hiring data scientists in the Chicago area, please let me know.

Thanks for reading!



<!--  -->
<!-- There are lots of websites/apps, including Pandora, Spotify and Amazon music that recommend music based on the music you like. From what I understand, Amazon's recommendations are generated by finding what other users with purchase history similar to yours also like. Pandora was among the first online recommendation systems, and initially had music experts rate music on several musical features. They now also have a up/down vote which they incorporate. Spotify is an extremely successful business whose recommendation algorithm is worth millions of dollars. My idea was to have customers rate music on several musical features, instead of experts. To do this, I used customer reviews of music to extract topics and analyzed the sentiment of each review to give the music a rating on that topic.

Since I was using historical customer reviews, I couldn't actually dictate the topics the customers should rate the music on. Rather, I had to find out what latent topics the customers *were* writing about. This was exciting, because the nuance of the language the customers used revealed surprising relationships between music. For example, customers might praise both Taylor Swift and Aretha Franklin for "female vocals".  -->